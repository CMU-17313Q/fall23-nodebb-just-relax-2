{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57602a97-0078-4801-b22a-51c9e65bf4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d756ef8",
   "metadata": {},
   "source": [
    "As the previous engineer left in a hurry, the model that was provided to you is pre-trained and you do not have any information on how it was trained. You are tasked with evaluating the model's performance and fairness.\n",
    "\n",
    "When it comes to training the model itself, the ML engineer who worked on the project before you had the following assumptions:\n",
    "\n",
    "The model is used to predict whether a student will be a good candidate for a software engineering job. It is a binary classifier, where 1 means the student is a good candidate, and 0 means the student is not a good candidate.\n",
    "The model is trained on a dataset of students who have graduated from CMU, and have been working in the industry for at least 1 year.\n",
    "In order to prevent bias, they assumed that removing Gender (M, F) and Student ID from the dataset would be sufficient when it comes to training the model. They claimed that it is now Group Unaware, thus the model would be fair.\n",
    "The model specification is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da8503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X variable (input parameters)\n",
    "# - Age (18 - 25)\n",
    "# - Major (Computer Science, Information Systems, Business, Math,\n",
    "#          Electrical and Computer Engineering, Statistics and Machine Learning)\n",
    "# - GPA (0 - 4.0)\n",
    "# - Extra Curricular Activities (Student Theatre, Buggy, Teaching Assistant, Student Government,\n",
    "#     Society of Women Engineers, Women in CS, Volleyball, Sorority, Men's Basketball,\n",
    "#     American Football, Men's Golf, Fraternity)\n",
    "# - Number of Programming Languages (1, 2, 3, 4, 5)\n",
    "# - Number of Past Internships (0, 1, 2, 3, 4)\n",
    "\n",
    "# Y variable (output)\n",
    "# - Good Candidate (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3523aa",
   "metadata": {},
   "source": [
    "The previous engineer has provided some examples on the usage of the model in the draft pull request.\n",
    "You are provided with a test dataset, which contains a similar set of features and output (whether the student is a good candidate or not). This test dataset is a different set of students from the training dataset, and the evaluation of whether the student is a good candidate is done by a fair panel of recruiters, so it can be considered to be unbiased. Additionally, the panel of recruiters have provided you with additional context on the extracurricular activities in comments (marked with #).\n",
    "\n",
    "Your test dataset is provided to you in the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8574507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X variable\n",
    "# - Student ID\n",
    "# - Gender (M, F)\n",
    "# - Age (18 - 25)\n",
    "# - Major (Computer Science, Information Systems, Business, Math,\n",
    "#          Electrical and Computer Engineering, Statistics and Machine Learning)\n",
    "# - GPA (0 - 4.0)\n",
    "# - Extra Curricular Activities (Student Theatre, Buggy, Teaching Assistant, Student Government,\n",
    "#     Society of Women Engineers, Women in CS, Volleyball, Sorority, Men's Basketball,\n",
    "#     American Football, Men's Golf, Fraternity)\n",
    "#   # Likely Co-Ed (Student Theatre, Buggy, Teaching Assistant, Student Government)\n",
    "#   # Likely Majority Female (Society of Women Engineers, Women in CS, Volleyball, Sorority)\n",
    "#   # Likely Majority Male (Men's Basketball, American Football, Men's Golf, Fraternity)\n",
    "# - Number of Programming Languages (1, 2, 3, 4, 5)\n",
    "# - Number of Past Internships (0, 1, 2, 3, 4)\n",
    "\n",
    "# Y variable\n",
    "# - Good Candidate (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeee217",
   "metadata": {},
   "source": [
    "Before doing a thorough evaluation of the fairness of the model, you will start by doing preliminary analysis on the test dataset, and run the model on the test dataset to get the accuracy of the model. To do so, you will need to set up a Jupyter notebook to do this, you can either:\n",
    "\n",
    "Use Google Colab to run the notebook in the cloud. (Recommended if you do not have experience with Jupyter notebooks)\n",
    "Alternatively, set up a JupyterLab on your local machine. Additionally, you can use VSCode to run the notebook as well. (Recommended if you are experienced)\n",
    "It is recommended that you use Python 3.9 or above when setting up the notebook.\n",
    "\n",
    "After you have set up the notebook, you should:\n",
    "\n",
    "Load the model and test dataset\n",
    "Plot the distribution of the test dataset across all features (except Student ID) using any visualization library of your choice (e.g. pandas, matplotlib, seaborn, plotly, etc.). You should choose the appropriate visualization for each feature.\n",
    "Predict the output of the test dataset using the model\n",
    "Report the accuracy of the model, and the confusion matrix\n",
    "Refer to the Resources & Documentation section if you need help with any of the above steps.\n",
    "\n",
    "By the checkpoint deadline, your team will commit the Jupyter notebook to your repository, and submit a link to the Jupyter notebook with the basic analysis and usage of the model done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69247e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⠀⢀⡤⢚⡭⣿⡟⠉⠉⠀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠁⠉⠁⠀⠀⠀⠉⠉⠁⠀⠉⣿⠀⠀⠀⠀⠀\n",
    "# ⠀⠀⠀⢁⢶⡟⠀⠀⠀⠘⠀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡀⠸⠀⠀⠀⠀⡆⠁⢀⠀⡇⠠⣼⡄⠀⠀⠀⠀\n",
    "# ⠀⠀⢠⠏⣾⠁⡄⠀⠀⡃⠀⢡⠀⠀⠀⠃⠀⠀⠀⠀⠀⠀⠀⡁⠀⠀⢠⠂⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⣇⠇⠀⢀⡄⢸⢀⡆⢸⡰⡆⢸⠿⣧⠀⠀⠀⠀\n",
    "# ⠀⠀⡜⣰⡏⠀⠧⠂⠰⠇⢰⣸⡄⠀⣼⡀⠀⠄⢠⠀⡀⠀⢠⡇⠀⢀⢾⠀⠀⢀⠇⠀⠀⠀⠀⠀⠀⡀⣸⠀⢀⢸⡟⠀⠀⡼⠀⡇⣼⡁⠆⡇⣧⢸⠀⠈⠀⠀⠀⠀\n",
    "# ⠀⢠⣷⠇⠀⢸⢸⠀⢰⠄⣸⡟⡇⢀⠽⡇⢀⡇⠘⠰⠁⠀⡞⡇⠀⡜⢸⡀⠀⣸⡄⠀⢀⠀⠀⢀⠴⢃⡇⢀⣇⠞⣓⠲⣴⠁⢸⢰⡇⢧⠀⣸⢿⣼⠀⠀⠀⠀⠀⠀\n",
    "# ⠀⣼⡏⢀⡆⠘⢸⠀⢸⠀⣿⣤⡇⣸⠀⡇⢸⡆⠂⢸⠀⢰⠇⡇⢰⠗⢻⡃⢸⣿⠀⠀⢸⠀⢀⡏⠀⣋⠅⣼⠋⣼⣿⡇⣇⠀⣿⠏⣧⢸⢠⣿⠀⠻⠀⠀⠀⠀⠀⠀\n",
    "# ⢠⣿⢀⡞⠀⡀⢸⢀⠸⣾⣿⣹⣇⡇⣄⡇⣼⡇⠀⣼⠀⡾⠉⢱⡞⠀⢀⡇⡞⢹⠀⠀⣾⠀⣼⡇⢠⣿⢠⠇⠘⣿⡇⢣⣸⡄⡞⠀⣿⠈⣿⡏⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "# ⢸⣿⢻⠇⣠⡇⣹⢸⡆⣿⠿⣿⣿⣄⢸⡇⡏⢿⡮⢹⢰⡇⣠⣼⡷⣶⣿⣿⣁⢘⠠⠇⣿⢰⣱⡁⣸⣿⡼⠀⣾⠿⠏⢸⢋⣿⣷⣤⠙⣇⣿⣇⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "# ⠾⠁⠘⡰⢋⣧⣇⣸⣷⡞⠓⠺⢧⣘⣆⢻⠇⢸⡇⣸⣞⣹⡿⠛⠻⣏⣀⡭⠙⢛⡶⠦⣟⢫⣿⡿⠉⣿⠇⠀⡿⠁⠀⢧⣞⣿⡇⢻⣧⡘⣿⣿⡆⠀⠀⠀⠀⠀⠀⠀\n",
    "# ⠀⢠⡿⠁⢸⠇⣼⠋⡿⣧⡀⠀⠀⠙⣿⡿⠀⢹⣶⠟⠋⠛⠻⠶⣤⣀⠀⠠⠔⠋⣣⣾⡏⡞⢸⠃⠀⡿⠀⠀⠁⠀⡰⠋⠘⠾⡇⠀⠙⠳⣿⣿⣿⡀⠀⠀⠀⠀⠀⠀\n",
    "# ⠀⡾⠁⢀⡏⢰⠃⠀⡇⢿⠿⣿⣿⣿⣿⠷⠶⠾⢿⣦⣀⣀⣀⣀⣈⣿⣇⢀⣴⠟⠉⢸⡿⠁⠊⠀⠀⠃⣀⣄⣠⠞⠁⠀⠀⠀⠀⠀⠀⣰⣿⣿⣿⣷⣦⣀⠀⠀⠀⠀\n",
    "# ⠈⠁⠀⠼⠁⠁⠀⠀⠃⢸⠀⢹⡉⠛⠋⠀⠀⠀⠀⠻⢿⣿⣿⣿⣿⣿⣿⣛⡟⠀⠀⠛⠃⠀⠀⠀⠀⢠⡿⠏⣠⡆⠀⠀⠀⠀⠀⣠⣾⣿⣿⣿⣿⣿⣿⣿⣿⣦⡀⠀\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠀⠀⢷⣤⡀⠀⠀⠀⠀⠀⠀⠈⠙⠛⠛⠋⠉⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⢾⠁⣰⣿⡇⠀⠀⠀⢀⣼⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣄\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠹⣿⢦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢟⣹⠀⠀⠀⣠⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⢾⣯⣄⣀⡀⠀⠀⠀⠀⣀⡤⠖⠋⠀⠀⠀⠀⠀⢀⣠⡤⠀⠀⠀⢺⣿⡀⢀⣼⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⠀⠀⢀⣩⡗⠒⠒⠉⠀⠀⠀⠀⠀⠀⠀⣠⣴⣿⠏⠀⠀⠀⠀⣾⠏⣰⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠧⠴⢿⡋⠁⠀⠀⠀⠀⠀⠀⠀⠀⣠⣞⢻⠟⠁⠀⠀⠀⠀⠀⣡⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢳⣄⡀⠀⠀⠀⠀⣀⣴⣮⣹⡿⠃⠀⠀⠀⠀⣀⣴⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
