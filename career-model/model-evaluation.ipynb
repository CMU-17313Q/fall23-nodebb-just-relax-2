{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f51779a",
   "metadata": {},
   "source": [
    "First we install the requirements as mentioned in the README.md file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c859ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib==1.2.0 in /home/hjoad/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.2.0)\n",
      "Collecting numpy==1.24.2 (from -r requirements.txt (line 2))\n",
      "  Downloading numpy-1.24.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas==1.5.3 (from -r requirements.txt (line 3))\n",
      "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic==1.10.6 (from -r requirements.txt (line 4))\n",
      "  Downloading pydantic-1.10.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil==2.8.2 in /home/hjoad/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (2.8.2)\n",
      "Collecting pytz==2022.7.1 (from -r requirements.txt (line 6))\n",
      "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn==1.2.1 (from -r requirements.txt (line 7))\n",
      "  Downloading scikit_learn-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting scipy==1.10.1 (from -r requirements.txt (line 8))\n",
      "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six==1.16.0 in /home/hjoad/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (1.16.0)\n",
      "Collecting threadpoolctl==3.1.0 (from -r requirements.txt (line 10))\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting typing_extensions==4.5.0 (from -r requirements.txt (line 11))\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: pytz, typing_extensions, threadpoolctl, numpy, scipy, pydantic, pandas, scikit-learn\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2023.3.post1\n",
      "    Uninstalling pytz-2023.3.post1:\n",
      "      Successfully uninstalled pytz-2023.3.post1\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 2.2.0\n",
      "    Uninstalling threadpoolctl-2.2.0:\n",
      "      Successfully uninstalled threadpoolctl-2.2.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.11.1\n",
      "    Uninstalling scipy-1.11.1:\n",
      "      Successfully uninstalled scipy-1.11.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.8\n",
      "    Uninstalling pydantic-1.10.8:\n",
      "      Successfully uninstalled pydantic-1.10.8\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.3\n",
      "    Uninstalling pandas-2.0.3:\n",
      "      Successfully uninstalled pandas-2.0.3\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.0\n",
      "    Uninstalling scikit-learn-1.3.0:\n",
      "      Successfully uninstalled scikit-learn-1.3.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.4.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.4.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "conda-repo-cli 1.0.75 requires requests_mock, which is not installed.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires PyYAML==6.0.1, but you have pyyaml 6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.24.2 pandas-1.5.3 pydantic-1.10.6 pytz-2022.7.1 scikit-learn-1.2.1 scipy-1.10.1 threadpoolctl-3.1.0 typing_extensions-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daca6af",
   "metadata": {},
   "source": [
    "Import all the dependencies needed for the predict function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c12c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic.tools import parse_obj_as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Pydantic models for data validation and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ea0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic Models\n",
    "class Student(BaseModel):\n",
    "    student_id: str = Field(alias=\"Student ID\")\n",
    "    gender: str = Field(alias=\"Gender\")\n",
    "    age: str = Field(alias=\"Age\")\n",
    "    major: str = Field(alias=\"Major\")\n",
    "    gpa: str = Field(alias=\"GPA\")\n",
    "    extra_curricular: str = Field(alias=\"Extra Curricular\")\n",
    "    num_programming_languages: str = Field(alias=\"Num Programming Languages\")\n",
    "    num_past_internships: str = Field(alias=\"Num Past Internships\")\n",
    "\n",
    "    class Config:\n",
    "        allow_population_by_field_name = True\n",
    "\n",
    "class PredictionResult(BaseModel):\n",
    "    good_employee: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the predict function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb6b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Functionality\n",
    "def predict(student):\n",
    "    '''\n",
    "    Returns a prediction on whether the student will be a good employee\n",
    "    based on given parameters by using the ML model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    student : dict\n",
    "        A dictionary that contains all fields in Student\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary satisfying type PredictionResult, contains a single field\n",
    "        'good_employee' which is either 1 (will be a good employee) or 0 (will\n",
    "        not be a good employee)\n",
    "    '''\n",
    "    # Use Pydantic to validate model fields exist\n",
    "    student = parse_obj_as(Student, student)\n",
    "\n",
    "    clf = joblib.load('./model.pkl')\n",
    "    \n",
    "    student = student.dict(by_alias=True)\n",
    "    query = pd.DataFrame(student, index=[0])\n",
    "    prediction = clf.predict(query) # TODO: Error handling ??\n",
    "\n",
    "    return { 'good_employee': prediction[0] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the code above was provided in the draft pull request. Now we will use the sample from the README.md file to make sure it works as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48d2f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = {\n",
    "        \"student_id\": \"student1\",\n",
    "        \"major\": \"Computer Science\",\n",
    "        \"age\": \"20\",\n",
    "        \"gender\": \"M\",\n",
    "        \"gpa\": \"4.0\",\n",
    "        \"extra_curricular\": \"Men's Basketball\",\n",
    "        \"num_programming_languages\": \"1\",\n",
    "        \"num_past_internships\": \"2\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8249268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'good_employee': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(student)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works :) Now we can start evaluating the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Model Performance & Fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't know how the model provided in the draft pull request was trained, we want to evaluate it before implementing it into NodeBB. In the rest of the notebook, we will be evaluating the model's performance and fairness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The engineer who created the model made the following assumptions:\n",
    "- The model is used to predict whether a student will be a good candidate for a software engineering job.\n",
    "- It is a binary classifier, where 1 means the student is a good candidate, and 0 means the student is not a good candidate.\n",
    "- The model is trained on a dataset of students who have graduated from CMU, and have been working in the industry for at least 1 year.\n",
    "- In order to prevent bias, they assumed that removing Gender (M, F) and Student ID from the dataset would be sufficient when it comes to training the model. They claimed that it is now Group Unaware, thus the model would be fair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model specification is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da8503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X variable (input parameters)\n",
    "# - Age (18 - 25)\n",
    "# - Major (Computer Science, Information Systems, Business, Math,\n",
    "#          Electrical and Computer Engineering, Statistics and Machine Learning)\n",
    "# - GPA (0 - 4.0)\n",
    "# - Extra Curricular Activities (Student Theatre, Buggy, Teaching Assistant, Student Government,\n",
    "#     Society of Women Engineers, Women in CS, Volleyball, Sorority, Men's Basketball,\n",
    "#     American Football, Men's Golf, Fraternity)\n",
    "# - Number of Programming Languages (1, 2, 3, 4, 5)\n",
    "# - Number of Past Internships (0, 1, 2, 3, 4)\n",
    "\n",
    "# Y variable (output)\n",
    "# - Good Candidate (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3523aa",
   "metadata": {},
   "source": [
    "The previous engineer has provided some examples on the usage of the model in the draft pull request.\n",
    "You are provided with a test dataset, which contains a similar set of features and output (whether the student is a good candidate or not). This test dataset is a different set of students from the training dataset, and the evaluation of whether the student is a good candidate is done by a fair panel of recruiters, so it can be considered to be unbiased. Additionally, the panel of recruiters have provided you with additional context on the extracurricular activities in comments (marked with #).\n",
    "\n",
    "Your test dataset is provided to you in the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8574507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X variable\n",
    "# - Student ID\n",
    "# - Gender (M, F)\n",
    "# - Age (18 - 25)\n",
    "# - Major (Computer Science, Information Systems, Business, Math,\n",
    "#          Electrical and Computer Engineering, Statistics and Machine Learning)\n",
    "# - GPA (0 - 4.0)\n",
    "# - Extra Curricular Activities (Student Theatre, Buggy, Teaching Assistant, Student Government,\n",
    "#     Society of Women Engineers, Women in CS, Volleyball, Sorority, Men's Basketball,\n",
    "#     American Football, Men's Golf, Fraternity)\n",
    "#   # Likely Co-Ed (Student Theatre, Buggy, Teaching Assistant, Student Government)\n",
    "#   # Likely Majority Female (Society of Women Engineers, Women in CS, Volleyball, Sorority)\n",
    "#   # Likely Majority Male (Men's Basketball, American Football, Men's Golf, Fraternity)\n",
    "# - Number of Programming Languages (1, 2, 3, 4, 5)\n",
    "# - Number of Past Internships (0, 1, 2, 3, 4)\n",
    "\n",
    "# Y variable\n",
    "# - Good Candidate (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeee217",
   "metadata": {},
   "source": [
    "Before doing a thorough evaluation of the fairness of the model, you will start by doing preliminary analysis on the test dataset, and run the model on the test dataset to get the accuracy of the model. To do so, you will need to set up a Jupyter notebook to do this, you can either:\n",
    "\n",
    "Use Google Colab to run the notebook in the cloud. (Recommended if you do not have experience with Jupyter notebooks)\n",
    "Alternatively, set up a JupyterLab on your local machine. Additionally, you can use VSCode to run the notebook as well. (Recommended if you are experienced)\n",
    "It is recommended that you use Python 3.9 or above when setting up the notebook.\n",
    "\n",
    "After you have set up the notebook, you should:\n",
    "\n",
    "Load the model and test dataset\n",
    "Plot the distribution of the test dataset across all features (except Student ID) using any visualization library of your choice (e.g. pandas, matplotlib, seaborn, plotly, etc.). You should choose the appropriate visualization for each feature.\n",
    "Predict the output of the test dataset using the model\n",
    "Report the accuracy of the model, and the confusion matrix\n",
    "Refer to the Resources & Documentation section if you need help with any of the above steps.\n",
    "\n",
    "By the checkpoint deadline, your team will commit the Jupyter notebook to your repository, and submit a link to the Jupyter notebook with the basic analysis and usage of the model done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69247e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⠀⢀⡤⢚⡭⣿⡟⠉⠉⠀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠁⠉⠁⠀⠀⠀⠉⠉⠁⠀⠉⣿⠀⠀⠀⠀⠀\n",
    "# ⠀⠀⠀⢁⢶⡟⠀⠀⠀⠘⠀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡀⠸⠀⠀⠀⠀⡆⠁⢀⠀⡇⠠⣼⡄⠀⠀⠀⠀\n",
    "# ⠀⠀⢠⠏⣾⠁⡄⠀⠀⡃⠀⢡⠀⠀⠀⠃⠀⠀⠀⠀⠀⠀⠀⡁⠀⠀⢠⠂⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⣇⠇⠀⢀⡄⢸⢀⡆⢸⡰⡆⢸⠿⣧⠀⠀⠀⠀\n",
    "# ⠀⠀⡜⣰⡏⠀⠧⠂⠰⠇⢰⣸⡄⠀⣼⡀⠀⠄⢠⠀⡀⠀⢠⡇⠀⢀⢾⠀⠀⢀⠇⠀⠀⠀⠀⠀⠀⡀⣸⠀⢀⢸⡟⠀⠀⡼⠀⡇⣼⡁⠆⡇⣧⢸⠀⠈⠀⠀⠀⠀\n",
    "# ⠀⢠⣷⠇⠀⢸⢸⠀⢰⠄⣸⡟⡇⢀⠽⡇⢀⡇⠘⠰⠁⠀⡞⡇⠀⡜⢸⡀⠀⣸⡄⠀⢀⠀⠀⢀⠴⢃⡇⢀⣇⠞⣓⠲⣴⠁⢸⢰⡇⢧⠀⣸⢿⣼⠀⠀⠀⠀⠀⠀\n",
    "# ⠀⣼⡏⢀⡆⠘⢸⠀⢸⠀⣿⣤⡇⣸⠀⡇⢸⡆⠂⢸⠀⢰⠇⡇⢰⠗⢻⡃⢸⣿⠀⠀⢸⠀⢀⡏⠀⣋⠅⣼⠋⣼⣿⡇⣇⠀⣿⠏⣧⢸⢠⣿⠀⠻⠀⠀⠀⠀⠀⠀\n",
    "# ⢠⣿⢀⡞⠀⡀⢸⢀⠸⣾⣿⣹⣇⡇⣄⡇⣼⡇⠀⣼⠀⡾⠉⢱⡞⠀⢀⡇⡞⢹⠀⠀⣾⠀⣼⡇⢠⣿⢠⠇⠘⣿⡇⢣⣸⡄⡞⠀⣿⠈⣿⡏⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "# ⢸⣿⢻⠇⣠⡇⣹⢸⡆⣿⠿⣿⣿⣄⢸⡇⡏⢿⡮⢹⢰⡇⣠⣼⡷⣶⣿⣿⣁⢘⠠⠇⣿⢰⣱⡁⣸⣿⡼⠀⣾⠿⠏⢸⢋⣿⣷⣤⠙⣇⣿⣇⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "# ⠾⠁⠘⡰⢋⣧⣇⣸⣷⡞⠓⠺⢧⣘⣆⢻⠇⢸⡇⣸⣞⣹⡿⠛⠻⣏⣀⡭⠙⢛⡶⠦⣟⢫⣿⡿⠉⣿⠇⠀⡿⠁⠀⢧⣞⣿⡇⢻⣧⡘⣿⣿⡆⠀⠀⠀⠀⠀⠀⠀\n",
    "# ⠀⢠⡿⠁⢸⠇⣼⠋⡿⣧⡀⠀⠀⠙⣿⡿⠀⢹⣶⠟⠋⠛⠻⠶⣤⣀⠀⠠⠔⠋⣣⣾⡏⡞⢸⠃⠀⡿⠀⠀⠁⠀⡰⠋⠘⠾⡇⠀⠙⠳⣿⣿⣿⡀⠀⠀⠀⠀⠀⠀\n",
    "# ⠀⡾⠁⢀⡏⢰⠃⠀⡇⢿⠿⣿⣿⣿⣿⠷⠶⠾⢿⣦⣀⣀⣀⣀⣈⣿⣇⢀⣴⠟⠉⢸⡿⠁⠊⠀⠀⠃⣀⣄⣠⠞⠁⠀⠀⠀⠀⠀⠀⣰⣿⣿⣿⣷⣦⣀⠀⠀⠀⠀\n",
    "# ⠈⠁⠀⠼⠁⠁⠀⠀⠃⢸⠀⢹⡉⠛⠋⠀⠀⠀⠀⠻⢿⣿⣿⣿⣿⣿⣿⣛⡟⠀⠀⠛⠃⠀⠀⠀⠀⢠⡿⠏⣠⡆⠀⠀⠀⠀⠀⣠⣾⣿⣿⣿⣿⣿⣿⣿⣿⣦⡀⠀\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠀⠀⢷⣤⡀⠀⠀⠀⠀⠀⠀⠈⠙⠛⠛⠋⠉⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⢾⠁⣰⣿⡇⠀⠀⠀⢀⣼⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣄\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠹⣿⢦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢟⣹⠀⠀⠀⣠⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⢾⣯⣄⣀⡀⠀⠀⠀⠀⣀⡤⠖⠋⠀⠀⠀⠀⠀⢀⣠⡤⠀⠀⠀⢺⣿⡀⢀⣼⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⠀⠀⢀⣩⡗⠒⠒⠉⠀⠀⠀⠀⠀⠀⠀⣠⣴⣿⠏⠀⠀⠀⠀⣾⠏⣰⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠧⠴⢿⡋⠁⠀⠀⠀⠀⠀⠀⠀⠀⣠⣞⢻⠟⠁⠀⠀⠀⠀⠀⣡⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢳⣄⡀⠀⠀⠀⠀⣀⣴⣮⣹⡿⠃⠀⠀⠀⠀⣀⣴⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
