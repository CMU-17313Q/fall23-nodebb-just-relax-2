{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f51779a",
   "metadata": {},
   "source": [
    "First we install the requirements as mentioned in the README.md file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c859ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib==1.2.0 in /home/hjoad/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.2.0)\n",
      "Collecting numpy==1.24.2 (from -r requirements.txt (line 2))\n",
      "  Downloading numpy-1.24.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas==1.5.3 (from -r requirements.txt (line 3))\n",
      "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic==1.10.6 (from -r requirements.txt (line 4))\n",
      "  Downloading pydantic-1.10.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil==2.8.2 in /home/hjoad/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (2.8.2)\n",
      "Collecting pytz==2022.7.1 (from -r requirements.txt (line 6))\n",
      "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn==1.2.1 (from -r requirements.txt (line 7))\n",
      "  Downloading scikit_learn-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting scipy==1.10.1 (from -r requirements.txt (line 8))\n",
      "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six==1.16.0 in /home/hjoad/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (1.16.0)\n",
      "Collecting threadpoolctl==3.1.0 (from -r requirements.txt (line 10))\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting typing_extensions==4.5.0 (from -r requirements.txt (line 11))\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: pytz, typing_extensions, threadpoolctl, numpy, scipy, pydantic, pandas, scikit-learn\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2023.3.post1\n",
      "    Uninstalling pytz-2023.3.post1:\n",
      "      Successfully uninstalled pytz-2023.3.post1\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 2.2.0\n",
      "    Uninstalling threadpoolctl-2.2.0:\n",
      "      Successfully uninstalled threadpoolctl-2.2.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.11.1\n",
      "    Uninstalling scipy-1.11.1:\n",
      "      Successfully uninstalled scipy-1.11.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.8\n",
      "    Uninstalling pydantic-1.10.8:\n",
      "      Successfully uninstalled pydantic-1.10.8\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.3\n",
      "    Uninstalling pandas-2.0.3:\n",
      "      Successfully uninstalled pandas-2.0.3\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.0\n",
      "    Uninstalling scikit-learn-1.3.0:\n",
      "      Successfully uninstalled scikit-learn-1.3.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.4.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.4.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "conda-repo-cli 1.0.75 requires requests_mock, which is not installed.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires PyYAML==6.0.1, but you have pyyaml 6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.24.2 pandas-1.5.3 pydantic-1.10.6 pytz-2022.7.1 scikit-learn-1.2.1 scipy-1.10.1 threadpoolctl-3.1.0 typing_extensions-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daca6af",
   "metadata": {},
   "source": [
    "Import all the dependencies needed for the predict function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c12c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic.tools import parse_obj_as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Pydantic models for data validation and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ea0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic Models\n",
    "class Student(BaseModel):\n",
    "    student_id: str = Field(alias=\"Student ID\")\n",
    "    gender: str = Field(alias=\"Gender\")\n",
    "    age: str = Field(alias=\"Age\")\n",
    "    major: str = Field(alias=\"Major\")\n",
    "    gpa: str = Field(alias=\"GPA\")\n",
    "    extra_curricular: str = Field(alias=\"Extra Curricular\")\n",
    "    num_programming_languages: str = Field(alias=\"Num Programming Languages\")\n",
    "    num_past_internships: str = Field(alias=\"Num Past Internships\")\n",
    "\n",
    "    class Config:\n",
    "        allow_population_by_field_name = True\n",
    "\n",
    "class PredictionResult(BaseModel):\n",
    "    good_employee: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the predict function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb6b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Functionality\n",
    "def predict(student):\n",
    "    '''\n",
    "    Returns a prediction on whether the student will be a good employee\n",
    "    based on given parameters by using the ML model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    student : dict\n",
    "        A dictionary that contains all fields in Student\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary satisfying type PredictionResult, contains a single field\n",
    "        'good_employee' which is either 1 (will be a good employee) or 0 (will\n",
    "        not be a good employee)\n",
    "    '''\n",
    "    # Use Pydantic to validate model fields exist\n",
    "    student = parse_obj_as(Student, student)\n",
    "\n",
    "    clf = joblib.load('./model.pkl')\n",
    "    \n",
    "    student = student.dict(by_alias=True)\n",
    "    query = pd.DataFrame(student, index=[0])\n",
    "    prediction = clf.predict(query) # TODO: Error handling ??\n",
    "\n",
    "    return { 'good_employee': prediction[0] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the code above was provided in the draft pull request. Now we will use the sample from the README.md file to make sure it works as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48d2f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = {\n",
    "        \"student_id\": \"student1\",\n",
    "        \"major\": \"Computer Science\",\n",
    "        \"age\": \"20\",\n",
    "        \"gender\": \"M\",\n",
    "        \"gpa\": \"4.0\",\n",
    "        \"extra_curricular\": \"Men's Basketball\",\n",
    "        \"num_programming_languages\": \"1\",\n",
    "        \"num_past_internships\": \"2\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8249268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'good_employee': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(student)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works :) Now we can start evaluating the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Model Performance & Fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't know how the model provided in the draft pull request was trained, we want to evaluate it before implementing it into NodeBB. In the rest of the notebook, we will be evaluating the model's performance and fairness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The engineer who created the model made the following assumptions:\n",
    "- The model is used to predict whether a student will be a good candidate for a software engineering job.\n",
    "- It is a binary classifier, where 1 means the student is a good candidate, and 0 means the student is not a good candidate.\n",
    "- The model is trained on a dataset of students who have graduated from CMU, and have been working in the industry for at least 1 year.\n",
    "- In order to prevent bias, they assumed that removing Gender (M, F) and Student ID from the dataset would be sufficient when it comes to training the model. They claimed that it is now Group Unaware, thus the model would be fair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model specification is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da8503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X variable (input parameters)\n",
    "# - Age (18 - 25)\n",
    "# - Major (Computer Science, Information Systems, Business, Math,\n",
    "#          Electrical and Computer Engineering, Statistics and Machine Learning)\n",
    "# - GPA (0 - 4.0)\n",
    "# - Extra Curricular Activities (Student Theatre, Buggy, Teaching Assistant, Student Government,\n",
    "#     Society of Women Engineers, Women in CS, Volleyball, Sorority, Men's Basketball,\n",
    "#     American Football, Men's Golf, Fraternity)\n",
    "# - Number of Programming Languages (1, 2, 3, 4, 5)\n",
    "# - Number of Past Internships (0, 1, 2, 3, 4)\n",
    "\n",
    "# Y variable (output)\n",
    "# - Good Candidate (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3523aa",
   "metadata": {},
   "source": [
    "A test dataset has been provided to us in the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8574507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X variable\n",
    "# - Student ID\n",
    "# - Gender (M, F)\n",
    "# - Age (18 - 25)\n",
    "# - Major (Computer Science, Information Systems, Business, Math,\n",
    "#          Electrical and Computer Engineering, Statistics and Machine Learning)\n",
    "# - GPA (0 - 4.0)\n",
    "# - Extra Curricular Activities (Student Theatre, Buggy, Teaching Assistant, Student Government,\n",
    "#     Society of Women Engineers, Women in CS, Volleyball, Sorority, Men's Basketball,\n",
    "#     American Football, Men's Golf, Fraternity)\n",
    "#   # Likely Co-Ed (Student Theatre, Buggy, Teaching Assistant, Student Government)\n",
    "#   # Likely Majority Female (Society of Women Engineers, Women in CS, Volleyball, Sorority)\n",
    "#   # Likely Majority Male (Men's Basketball, American Football, Men's Golf, Fraternity)\n",
    "# - Number of Programming Languages (1, 2, 3, 4, 5)\n",
    "# - Number of Past Internships (0, 1, 2, 3, 4)\n",
    "\n",
    "# Y variable\n",
    "# - Good Candidate (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test dataset is a different set of students from the training dataset, and the evaluation of whether the student is a good candidate is done by a fair panel of recruiters, so it can be considered to be unbiased. Additionally, the panel of recruiters have provided us with additional context on the extracurricular activities in comments (marked with #)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we evaluate the fairness of the model, we want to do a prelimiary analysis on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model and Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we have to do is load the model and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "test_df = pd.read_csv(\"student_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Distributions of the Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to plot the distribution of the test dataset across all features (except Student ID). We will be using the ??? library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# libraries can be pandas, matplotlib, seaborn, plotly, etc.\n",
    "# choose the appropriate visualization for each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run the model on the test dataset to get the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to predict the output of the test dataset using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can report the accuracy of the model along with the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69247e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⠀⢀⡤⢚⡭⣿⡟⠉⠉⠀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠁⠉⠁⠀⠀⠀⠉⠉⠁⠀⠉⣿⠀⠀⠀⠀⠀\n",
    "# ⠀⠀⠀⢁⢶⡟⠀⠀⠀⠘⠀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡀⠸⠀⠀⠀⠀⡆⠁⢀⠀⡇⠠⣼⡄⠀⠀⠀⠀\n",
    "# ⠀⠀⢠⠏⣾⠁⡄⠀⠀⡃⠀⢡⠀⠀⠀⠃⠀⠀⠀⠀⠀⠀⠀⡁⠀⠀⢠⠂⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⣇⠇⠀⢀⡄⢸⢀⡆⢸⡰⡆⢸⠿⣧⠀⠀⠀⠀\n",
    "# ⠀⠀⡜⣰⡏⠀⠧⠂⠰⠇⢰⣸⡄⠀⣼⡀⠀⠄⢠⠀⡀⠀⢠⡇⠀⢀⢾⠀⠀⢀⠇⠀⠀⠀⠀⠀⠀⡀⣸⠀⢀⢸⡟⠀⠀⡼⠀⡇⣼⡁⠆⡇⣧⢸⠀⠈⠀⠀⠀⠀\n",
    "# ⠀⢠⣷⠇⠀⢸⢸⠀⢰⠄⣸⡟⡇⢀⠽⡇⢀⡇⠘⠰⠁⠀⡞⡇⠀⡜⢸⡀⠀⣸⡄⠀⢀⠀⠀⢀⠴⢃⡇⢀⣇⠞⣓⠲⣴⠁⢸⢰⡇⢧⠀⣸⢿⣼⠀⠀⠀⠀⠀⠀\n",
    "# ⠀⣼⡏⢀⡆⠘⢸⠀⢸⠀⣿⣤⡇⣸⠀⡇⢸⡆⠂⢸⠀⢰⠇⡇⢰⠗⢻⡃⢸⣿⠀⠀⢸⠀⢀⡏⠀⣋⠅⣼⠋⣼⣿⡇⣇⠀⣿⠏⣧⢸⢠⣿⠀⠻⠀⠀⠀⠀⠀⠀\n",
    "# ⢠⣿⢀⡞⠀⡀⢸⢀⠸⣾⣿⣹⣇⡇⣄⡇⣼⡇⠀⣼⠀⡾⠉⢱⡞⠀⢀⡇⡞⢹⠀⠀⣾⠀⣼⡇⢠⣿⢠⠇⠘⣿⡇⢣⣸⡄⡞⠀⣿⠈⣿⡏⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "# ⢸⣿⢻⠇⣠⡇⣹⢸⡆⣿⠿⣿⣿⣄⢸⡇⡏⢿⡮⢹⢰⡇⣠⣼⡷⣶⣿⣿⣁⢘⠠⠇⣿⢰⣱⡁⣸⣿⡼⠀⣾⠿⠏⢸⢋⣿⣷⣤⠙⣇⣿⣇⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "# ⠾⠁⠘⡰⢋⣧⣇⣸⣷⡞⠓⠺⢧⣘⣆⢻⠇⢸⡇⣸⣞⣹⡿⠛⠻⣏⣀⡭⠙⢛⡶⠦⣟⢫⣿⡿⠉⣿⠇⠀⡿⠁⠀⢧⣞⣿⡇⢻⣧⡘⣿⣿⡆⠀⠀⠀⠀⠀⠀⠀\n",
    "# ⠀⢠⡿⠁⢸⠇⣼⠋⡿⣧⡀⠀⠀⠙⣿⡿⠀⢹⣶⠟⠋⠛⠻⠶⣤⣀⠀⠠⠔⠋⣣⣾⡏⡞⢸⠃⠀⡿⠀⠀⠁⠀⡰⠋⠘⠾⡇⠀⠙⠳⣿⣿⣿⡀⠀⠀⠀⠀⠀⠀\n",
    "# ⠀⡾⠁⢀⡏⢰⠃⠀⡇⢿⠿⣿⣿⣿⣿⠷⠶⠾⢿⣦⣀⣀⣀⣀⣈⣿⣇⢀⣴⠟⠉⢸⡿⠁⠊⠀⠀⠃⣀⣄⣠⠞⠁⠀⠀⠀⠀⠀⠀⣰⣿⣿⣿⣷⣦⣀⠀⠀⠀⠀\n",
    "# ⠈⠁⠀⠼⠁⠁⠀⠀⠃⢸⠀⢹⡉⠛⠋⠀⠀⠀⠀⠻⢿⣿⣿⣿⣿⣿⣿⣛⡟⠀⠀⠛⠃⠀⠀⠀⠀⢠⡿⠏⣠⡆⠀⠀⠀⠀⠀⣠⣾⣿⣿⣿⣿⣿⣿⣿⣿⣦⡀⠀\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠀⠀⢷⣤⡀⠀⠀⠀⠀⠀⠀⠈⠙⠛⠛⠋⠉⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⢾⠁⣰⣿⡇⠀⠀⠀⢀⣼⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣄\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠹⣿⢦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢟⣹⠀⠀⠀⣠⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⢾⣯⣄⣀⡀⠀⠀⠀⠀⣀⡤⠖⠋⠀⠀⠀⠀⠀⢀⣠⡤⠀⠀⠀⢺⣿⡀⢀⣼⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⠀⠀⢀⣩⡗⠒⠒⠉⠀⠀⠀⠀⠀⠀⠀⣠⣴⣿⠏⠀⠀⠀⠀⣾⠏⣰⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠧⠴⢿⡋⠁⠀⠀⠀⠀⠀⠀⠀⠀⣠⣞⢻⠟⠁⠀⠀⠀⠀⠀⣡⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
    "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢳⣄⡀⠀⠀⠀⠀⣀⣴⣮⣹⡿⠃⠀⠀⠀⠀⣀⣴⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
